{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "trajectory = torch.load(\"./hidden_states_last.pt\",map_location=torch.device('cpu'))[0]\n",
        "\n",
        "trajectory.shape # gives you torch.Size([4095, 1536])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrQzTPa31JxR",
        "outputId": "e71d0194-29d5-42c7-d729-501b9e5a5d0b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4095, 1536])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sPAxzopN1AnY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\"\"\"\n",
        "gives you\n",
        "Overall reconstruction accuracy:\n",
        "using\n",
        "    latent_dim = 64\n",
        "\n",
        "\n",
        "or\n",
        "Overall reconstruction accuracy:\n",
        "using\n",
        "    latent_dim = 32\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.GELU(),\n",
        "            # nn.Linear(dim, dim),\n",
        "            # nn.Dropout(0.05),\n",
        "            # nn.LayerNorm(dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.fc(x)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super().__init__()\n",
        "        dims = [input_dim]\n",
        "        while dims[-1] // 2 >= latent_dim:\n",
        "            dims.append(dims[-1] // 2)\n",
        "        dims.append(latent_dim)\n",
        "\n",
        "        layers = []\n",
        "        for in_dim, out_dim in zip(dims[:-1], dims[1:]):\n",
        "            layers.append(nn.Linear(in_dim, out_dim))\n",
        "            if out_dim != latent_dim:\n",
        "                layers.append(nn.LayerNorm(out_dim))\n",
        "                layers.append(nn.GELU())\n",
        "                layers.append(ResidualBlock(out_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, latent_dim):\n",
        "        super().__init__()\n",
        "        dims = [latent_dim]\n",
        "        while dims[-1] * 2 <= output_dim:\n",
        "            dims.append(dims[-1] * 2)\n",
        "        dims.append(output_dim)\n",
        "\n",
        "        layers = []\n",
        "        for in_dim, out_dim in zip(dims[:-1], dims[1:]):\n",
        "            layers.append(nn.Linear(in_dim, out_dim))\n",
        "            if out_dim != output_dim:\n",
        "                layers.append(nn.LayerNorm(out_dim))\n",
        "                layers.append(nn.GELU())\n",
        "                layers.append(ResidualBlock(out_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def train_autoencoder(trajectory, latent_dim=64, batch_size=128, num_epochs=100, lr=1e-3):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # trajectory_lengths = [t.shape[0] for t in trajectory]\n",
        "    input_dim = trajectory.shape[1]\n",
        "\n",
        "    # stacked_trajectory = torch.cat(trajectory, dim=0)\n",
        "\n",
        "    # Create dataset and loader\n",
        "    dataset = TensorDataset(trajectory)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Initialize models\n",
        "    encoder = Encoder(input_dim, latent_dim).to(device)\n",
        "    decoder = Decoder(input_dim, latent_dim).to(device)\n",
        "\n",
        "    optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for (batch,) in loader:\n",
        "            x = batch.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            z = encoder(x)\n",
        "            x_recon = decoder(z)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(x_recon, x)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item() * x.size(0)\n",
        "\n",
        "        epoch_loss /= len(dataset)\n",
        "\n",
        "        # Evaluation\n",
        "        if epoch % 10 == 0 or epoch == num_epochs:\n",
        "            encoder.eval()\n",
        "            decoder.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # Compute Euclidean distance\n",
        "                val_batch = trajectory.to(device)\n",
        "                val_recon = decoder(encoder(val_batch))\n",
        "                # l2_dist = torch.norm(val_recon - val_batch, dim=1).mean().item()\n",
        "\n",
        "                # Cosine similarity\n",
        "                cos_sim = nn.functional.cosine_similarity(val_recon, val_batch, dim=1).mean().item()\n",
        "\n",
        "                print(f\"Epoch {epoch:03d} | Loss: {epoch_loss:.6f} | Cosine Sim: {cos_sim:.6f}\")\n",
        "\n",
        "            if epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "\n",
        "    return encoder, decoder\n",
        "\n",
        "def encode_trajectory(encoder, trajectory, device=None):\n",
        "    \"\"\"\n",
        "    Encode the entire trajectory tensor at once.\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    encoder.eval()\n",
        "    with torch.no_grad():\n",
        "        encoded_trajectory = encoder(trajectory.to(device))\n",
        "\n",
        "    return encoded_trajectory\n",
        "\n",
        "def decode_trajectory(decoder, encoded_trajectory, device=None):\n",
        "    \"\"\"\n",
        "    Decode the entire encoded trajectory tensor at once. Ensures input is at least 2D.\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    decoder.eval()\n",
        "    with torch.no_grad():\n",
        "        # Ensure input is at least 2D (batch, features)\n",
        "        if encoded_trajectory.dim() == 1:\n",
        "            encoded_trajectory = encoded_trajectory.unsqueeze(0)\n",
        "        decoded_trajectory = decoder(encoded_trajectory.to(device))\n",
        "\n",
        "    return decoded_trajectory\n",
        "\n",
        "def evaluate_reconstruction(original_trajectory, decoded_trajectory):\n",
        "    \"\"\"\n",
        "    Evaluate reconstruction quality for the entire trajectory tensor.\n",
        "    \"\"\"\n",
        "    if original_trajectory.device != decoded_trajectory.device:\n",
        "        decoded_trajectory = decoded_trajectory.to(original_trajectory.device)\n",
        "\n",
        "    # If input is 1D, unsqueeze to 2D for consistent metric calculation\n",
        "    if original_trajectory.dim() == 1:\n",
        "        original_trajectory = original_trajectory.unsqueeze(0)\n",
        "    if decoded_trajectory.dim() == 1:\n",
        "        decoded_trajectory = decoded_trajectory.unsqueeze(0)\n",
        "\n",
        "    # # L2 distance\n",
        "    # l2_dist = torch.norm(decoded_trajectory - original_trajectory, dim=1).mean().item()\n",
        "\n",
        "    # Cosine similarity\n",
        "    cos_sim = nn.functional.cosine_similarity(decoded_trajectory, original_trajectory, dim=1).mean().item()\n",
        "\n",
        "    return {\n",
        "        # \"avg_l2_distance\": l2_dist,\n",
        "        \"avg_cosine_similarity\": cos_sim\n",
        "    }\n",
        "\n",
        "\n",
        "def calculate_reconstruction_accuracy(encoder, decoder, trajectory, device=None):\n",
        "    \"\"\"\n",
        "    Calculate reconstruction accuracy as a percentage for the PyTorch autoencoder\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Get encoded and decoded trajectory\n",
        "    encoded_trajectory = encode_trajectory(encoder, trajectory, device)\n",
        "    decoded_trajectory = decode_trajectory(decoder, encoded_trajectory, device)\n",
        "\n",
        "    original_data = trajectory.cpu().numpy()\n",
        "    reconstructed_data = decoded_trajectory.cpu().numpy()\n",
        "\n",
        "    mse = np.mean(np.square(original_data - reconstructed_data))\n",
        "    variance = np.var(original_data)\n",
        "    accuracy_percentage = (1 - mse/variance) * 100\n",
        "\n",
        "    # Calculate component-wise accuracy\n",
        "    component_mse = np.mean(np.square(original_data - reconstructed_data), axis=0)\n",
        "    component_var = np.var(original_data, axis=0)\n",
        "    component_accuracy = np.mean((1 - component_mse/component_var) * 100)\n",
        "\n",
        "    metrics = evaluate_reconstruction(trajectory, decoded_trajectory)\n",
        "\n",
        "    print(\"\\nReconstruction Accuracy Metrics:\")\n",
        "    print(f\"Overall reconstruction accuracy: {accuracy_percentage:.2f}%\")\n",
        "    print(f\"Average component-wise accuracy: {component_accuracy:.2f}%\")\n",
        "    # print(f\"Average L2 Distance: {metrics['avg_l2_distance']:.6f}\")\n",
        "    print(f\"Average Cosine Similarity: {metrics['avg_cosine_similarity']:.6f}\")\n",
        "\n",
        "    return {\n",
        "        \"overall_accuracy\": accuracy_percentage,\n",
        "        \"component_accuracy\": (1 - component_mse/component_var) * 100,\n",
        "        # \"l2_distance\": metrics[\"avg_l2_distance\"],\n",
        "        \"cosine_similarity\": metrics[\"avg_cosine_similarity\"],\n",
        "        \"mse\": mse\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Hyperparameters\n",
        "    latent_dim = 128  # Target reduced dimension\n",
        "    batch_size = 64\n",
        "    lr = 1e-3\n",
        "    num_epochs = 100\n",
        "\n",
        "    encoder, decoder = train_autoencoder(\n",
        "        trajectory=trajectory,\n",
        "        latent_dim=latent_dim,\n",
        "        batch_size=batch_size,\n",
        "        num_epochs=num_epochs,\n",
        "        lr=lr\n",
        "    )\n",
        "\n",
        "    accuracy_metrics = calculate_reconstruction_accuracy(encoder, decoder, trajectory)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMVzGT-Q1NeY",
        "outputId": "d29a2ec3-f166-4950-c435-6aa14a91e30e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 010 | Loss: 2.164499 | L2 Dist: 54.098827 | Cosine Sim: 0.826256\n",
            "Epoch 020 | Loss: 1.472905 | L2 Dist: 43.233139 | Cosine Sim: 0.886581\n",
            "Epoch 030 | Loss: 1.151322 | L2 Dist: 37.557602 | Cosine Sim: 0.914403\n",
            "Epoch 040 | Loss: 0.931924 | L2 Dist: 33.475101 | Cosine Sim: 0.932438\n",
            "Epoch 050 | Loss: 0.775821 | L2 Dist: 30.296339 | Cosine Sim: 0.945106\n",
            "Epoch 060 | Loss: 0.672278 | L2 Dist: 28.389076 | Cosine Sim: 0.952792\n",
            "Epoch 070 | Loss: 0.592351 | L2 Dist: 26.875671 | Cosine Sim: 0.958523\n",
            "Epoch 080 | Loss: 0.512141 | L2 Dist: 24.584215 | Cosine Sim: 0.965322\n",
            "Epoch 090 | Loss: 0.455247 | L2 Dist: 23.378595 | Cosine Sim: 0.968979\n",
            "Epoch 100 | Loss: 0.415229 | L2 Dist: 22.150261 | Cosine Sim: 0.972448\n",
            "\n",
            "Reconstruction Accuracy Metrics:\n",
            "Overall reconstruction accuracy: 94.54%\n",
            "Average component-wise accuracy: 85.81%\n",
            "Average L2 Distance: 22.150261\n",
            "Average Cosine Similarity: 0.972448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Hyperparameters\n",
        "    latent_dim = 64  # Target reduced dimension\n",
        "    batch_size = 64\n",
        "    lr = 1e-3\n",
        "    num_epochs = 300\n",
        "\n",
        "    encoder, decoder = train_autoencoder(\n",
        "        trajectory=trajectory,\n",
        "        latent_dim=latent_dim,\n",
        "        batch_size=batch_size,\n",
        "        num_epochs=num_epochs,\n",
        "        lr=lr\n",
        "    )\n",
        "\n",
        "    accuracy_metrics = calculate_reconstruction_accuracy(encoder, decoder, trajectory)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_Tq2h5a1ZeL",
        "outputId": "e87caa6c-ebae-4396-d925-afaa89ee8643"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 010 | Loss: 3.583819 | L2 Dist: 71.893166 | Cosine Sim: 0.695943\n",
            "Epoch 020 | Loss: 2.709053 | L2 Dist: 61.984936 | Cosine Sim: 0.776878\n",
            "Epoch 030 | Loss: 2.299956 | L2 Dist: 56.233173 | Cosine Sim: 0.812155\n",
            "Epoch 040 | Loss: 2.035281 | L2 Dist: 52.203121 | Cosine Sim: 0.836630\n",
            "Epoch 050 | Loss: 1.852918 | L2 Dist: 50.156353 | Cosine Sim: 0.848085\n",
            "Epoch 060 | Loss: 1.722555 | L2 Dist: 47.375313 | Cosine Sim: 0.863865\n",
            "Epoch 070 | Loss: 1.725615 | L2 Dist: 47.210846 | Cosine Sim: 0.865913\n",
            "Epoch 080 | Loss: 1.553553 | L2 Dist: 44.222549 | Cosine Sim: 0.879287\n",
            "Epoch 090 | Loss: 1.448157 | L2 Dist: 42.270977 | Cosine Sim: 0.889200\n",
            "Epoch 100 | Loss: 1.428922 | L2 Dist: 42.197643 | Cosine Sim: 0.890330\n",
            "Epoch 110 | Loss: 1.311438 | L2 Dist: 39.971607 | Cosine Sim: 0.900601\n",
            "Epoch 120 | Loss: 1.289553 | L2 Dist: 39.447876 | Cosine Sim: 0.904458\n",
            "Epoch 130 | Loss: 1.216488 | L2 Dist: 38.596214 | Cosine Sim: 0.908966\n",
            "Epoch 140 | Loss: 1.178372 | L2 Dist: 37.997829 | Cosine Sim: 0.911829\n",
            "Epoch 150 | Loss: 1.183046 | L2 Dist: 37.327255 | Cosine Sim: 0.914244\n",
            "Epoch 160 | Loss: 1.063711 | L2 Dist: 35.786373 | Cosine Sim: 0.920379\n",
            "Epoch 170 | Loss: 1.012052 | L2 Dist: 34.772808 | Cosine Sim: 0.924801\n",
            "Epoch 180 | Loss: 0.986730 | L2 Dist: 34.077969 | Cosine Sim: 0.927954\n",
            "Epoch 190 | Loss: 0.939954 | L2 Dist: 33.392265 | Cosine Sim: 0.931366\n",
            "Epoch 200 | Loss: 0.921175 | L2 Dist: 32.708969 | Cosine Sim: 0.933935\n",
            "Epoch 210 | Loss: 0.859848 | L2 Dist: 31.767450 | Cosine Sim: 0.937973\n",
            "Epoch 220 | Loss: 0.853919 | L2 Dist: 31.514828 | Cosine Sim: 0.939184\n",
            "Epoch 230 | Loss: 0.822158 | L2 Dist: 30.957703 | Cosine Sim: 0.941445\n",
            "Epoch 240 | Loss: 0.799569 | L2 Dist: 31.067114 | Cosine Sim: 0.941321\n",
            "Epoch 250 | Loss: 0.766404 | L2 Dist: 29.815466 | Cosine Sim: 0.945902\n",
            "Epoch 260 | Loss: 0.723206 | L2 Dist: 29.213150 | Cosine Sim: 0.948006\n",
            "Epoch 270 | Loss: 0.719573 | L2 Dist: 28.747911 | Cosine Sim: 0.949835\n",
            "Epoch 280 | Loss: 0.689075 | L2 Dist: 28.476011 | Cosine Sim: 0.950909\n",
            "Epoch 290 | Loss: 0.698285 | L2 Dist: 29.095736 | Cosine Sim: 0.949817\n",
            "Epoch 300 | Loss: 0.658293 | L2 Dist: 27.601749 | Cosine Sim: 0.954144\n",
            "\n",
            "Reconstruction Accuracy Metrics:\n",
            "Overall reconstruction accuracy: 91.03%\n",
            "Average component-wise accuracy: 78.56%\n",
            "Average L2 Distance: 27.601749\n",
            "Average Cosine Similarity: 0.954144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Hyperparameters\n",
        "    latent_dim = 32  # Target reduced dimension\n",
        "    batch_size = 64\n",
        "    lr = 1e-3\n",
        "    num_epochs = 300\n",
        "\n",
        "    encoder, decoder = train_autoencoder(\n",
        "        trajectory=trajectory,\n",
        "        latent_dim=latent_dim,\n",
        "        batch_size=batch_size,\n",
        "        num_epochs=num_epochs,\n",
        "        lr=lr\n",
        "    )\n",
        "\n",
        "    accuracy_metrics = calculate_reconstruction_accuracy(encoder, decoder, trajectory)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZasDfvfadoRd",
        "outputId": "7c77b07d-24d9-4a8d-e752-b2b6d6f26639"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 010 | Loss: 3.114817 | L2 Dist: 66.351280 | Cosine Sim: 0.740156\n",
            "Epoch 020 | Loss: 2.861269 | L2 Dist: 64.184189 | Cosine Sim: 0.758287\n",
            "Epoch 030 | Loss: 2.839603 | L2 Dist: 63.470081 | Cosine Sim: 0.763982\n",
            "Epoch 040 | Loss: 2.831652 | L2 Dist: 62.443546 | Cosine Sim: 0.770601\n",
            "Epoch 050 | Loss: 2.657126 | L2 Dist: 61.149544 | Cosine Sim: 0.780942\n",
            "Epoch 060 | Loss: 2.756527 | L2 Dist: 61.567329 | Cosine Sim: 0.774983\n",
            "Epoch 070 | Loss: 2.668292 | L2 Dist: 60.274960 | Cosine Sim: 0.784556\n",
            "Epoch 080 | Loss: 2.540964 | L2 Dist: 59.017342 | Cosine Sim: 0.791408\n",
            "Epoch 090 | Loss: 2.789755 | L2 Dist: 63.970779 | Cosine Sim: 0.760134\n",
            "Epoch 100 | Loss: 2.791267 | L2 Dist: 63.636669 | Cosine Sim: 0.758669\n",
            "Epoch 110 | Loss: 2.610243 | L2 Dist: 60.317879 | Cosine Sim: 0.783802\n",
            "Epoch 120 | Loss: 2.760078 | L2 Dist: 62.243565 | Cosine Sim: 0.769706\n",
            "Epoch 130 | Loss: 2.672255 | L2 Dist: 60.666290 | Cosine Sim: 0.778828\n",
            "Epoch 140 | Loss: 2.519322 | L2 Dist: 58.571941 | Cosine Sim: 0.794818\n",
            "Epoch 150 | Loss: 2.382870 | L2 Dist: 57.738342 | Cosine Sim: 0.802352\n",
            "Epoch 160 | Loss: 2.227526 | L2 Dist: 55.516342 | Cosine Sim: 0.817536\n",
            "Epoch 170 | Loss: 2.179773 | L2 Dist: 54.664101 | Cosine Sim: 0.824567\n",
            "Epoch 180 | Loss: 1.977583 | L2 Dist: 52.111691 | Cosine Sim: 0.837388\n",
            "Epoch 190 | Loss: 1.943999 | L2 Dist: 49.676163 | Cosine Sim: 0.849849\n",
            "Epoch 200 | Loss: 1.756800 | L2 Dist: 48.019108 | Cosine Sim: 0.860534\n",
            "Epoch 210 | Loss: 1.697901 | L2 Dist: 46.691631 | Cosine Sim: 0.866435\n",
            "Epoch 220 | Loss: 1.596007 | L2 Dist: 44.729713 | Cosine Sim: 0.876164\n",
            "Epoch 230 | Loss: 1.585798 | L2 Dist: 44.379021 | Cosine Sim: 0.879679\n",
            "Epoch 240 | Loss: 1.496428 | L2 Dist: 43.084320 | Cosine Sim: 0.885681\n",
            "Epoch 250 | Loss: 1.412814 | L2 Dist: 41.736179 | Cosine Sim: 0.891878\n",
            "Epoch 260 | Loss: 1.373261 | L2 Dist: 41.423435 | Cosine Sim: 0.895462\n",
            "Epoch 270 | Loss: 1.310203 | L2 Dist: 40.142529 | Cosine Sim: 0.900469\n",
            "Epoch 280 | Loss: 1.248872 | L2 Dist: 38.790577 | Cosine Sim: 0.905674\n",
            "Epoch 290 | Loss: 1.221082 | L2 Dist: 38.693157 | Cosine Sim: 0.908127\n",
            "Epoch 300 | Loss: 1.190115 | L2 Dist: 38.552200 | Cosine Sim: 0.909585\n",
            "\n",
            "Reconstruction Accuracy Metrics:\n",
            "Overall reconstruction accuracy: 82.98%\n",
            "Average component-wise accuracy: 61.35%\n",
            "Average L2 Distance: 38.552200\n",
            "Average Cosine Similarity: 0.909585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Hyperparameters\n",
        "    latent_dim = 16  # Target reduced dimension\n",
        "    batch_size = 64\n",
        "    lr = 1e-3\n",
        "    num_epochs = 200\n",
        "\n",
        "    encoder, decoder = train_autoencoder(\n",
        "        trajectory=trajectory,\n",
        "        latent_dim=latent_dim,\n",
        "        batch_size=batch_size,\n",
        "        num_epochs=num_epochs,\n",
        "        lr=lr\n",
        "    )\n",
        "\n",
        "    accuracy_metrics = calculate_reconstruction_accuracy(encoder, decoder, trajectory)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDPrkpJ-WH_i",
        "outputId": "09a60e99-5d60-4896-c62c-c4c23c0a6c6f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 010 | Loss: 4.420108 | L2 Dist: 81.932358 | Cosine Sim: 0.580824\n",
            "Epoch 020 | Loss: 4.539783 | L2 Dist: 81.480064 | Cosine Sim: 0.585864\n",
            "Epoch 030 | Loss: 4.539593 | L2 Dist: 81.682335 | Cosine Sim: 0.586271\n",
            "Epoch 040 | Loss: 4.537394 | L2 Dist: 81.473518 | Cosine Sim: 0.586701\n",
            "Epoch 050 | Loss: 4.537432 | L2 Dist: 81.582283 | Cosine Sim: 0.586526\n",
            "Epoch 060 | Loss: 4.535830 | L2 Dist: 81.703156 | Cosine Sim: 0.586687\n",
            "Epoch 070 | Loss: 4.536656 | L2 Dist: 81.659943 | Cosine Sim: 0.586582\n",
            "Epoch 080 | Loss: 4.535079 | L2 Dist: 81.481506 | Cosine Sim: 0.586189\n",
            "Epoch 090 | Loss: 4.535240 | L2 Dist: 81.504601 | Cosine Sim: 0.586675\n",
            "Epoch 100 | Loss: 4.534337 | L2 Dist: 81.513275 | Cosine Sim: 0.586700\n",
            "Epoch 110 | Loss: 4.535802 | L2 Dist: 81.454285 | Cosine Sim: 0.586718\n",
            "Epoch 120 | Loss: 4.533437 | L2 Dist: 81.448212 | Cosine Sim: 0.586664\n",
            "Epoch 130 | Loss: 4.533291 | L2 Dist: 81.490891 | Cosine Sim: 0.586794\n",
            "Epoch 140 | Loss: 4.533193 | L2 Dist: 81.476738 | Cosine Sim: 0.586827\n",
            "Epoch 150 | Loss: 4.533013 | L2 Dist: 81.564003 | Cosine Sim: 0.586885\n",
            "Epoch 160 | Loss: 4.531811 | L2 Dist: 81.469238 | Cosine Sim: 0.587088\n",
            "Epoch 170 | Loss: 4.532288 | L2 Dist: 81.435844 | Cosine Sim: 0.587063\n",
            "Epoch 180 | Loss: 4.531176 | L2 Dist: 81.605865 | Cosine Sim: 0.586914\n",
            "Epoch 190 | Loss: 4.533201 | L2 Dist: 81.544472 | Cosine Sim: 0.586923\n",
            "Epoch 200 | Loss: 4.530806 | L2 Dist: 81.536629 | Cosine Sim: 0.587167\n",
            "\n",
            "Reconstruction Accuracy Metrics:\n",
            "Overall reconstruction accuracy: 34.07%\n",
            "Average component-wise accuracy: -0.18%\n",
            "Average L2 Distance: 81.536629\n",
            "Average Cosine Similarity: 0.587167\n"
          ]
        }
      ]
    }
  ]
}