{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4339,
     "status": "ok",
     "timestamp": 1745273327623,
     "user": {
      "displayName": "gorge ja",
      "userId": "06774668278947305934"
     },
     "user_tz": -120
    },
    "id": "S69gWNt0ZLvZ"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_trajectories(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        trajectories = pickle.load(f)\n",
    "    return trajectories\n",
    "trajectories = load_trajectories(\"./trajectories10.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53x2SJaDYjaX"
   },
   "source": [
    "For all trajectories together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77075,
     "status": "ok",
     "timestamp": 1745274712805,
     "user": {
      "displayName": "gorge ja",
      "userId": "06774668278947305934"
     },
     "user_tz": -120
    },
    "id": "5xke67loYh43",
    "outputId": "37975dd9-c14d-4233-b120-1897a1c29f85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Loss: 1.791686 | L2 Dist: 49.975746 | Cosine Sim: 0.867917\n",
      "Epoch 020 | Loss: 1.176212 | L2 Dist: 40.038967 | Cosine Sim: 0.917338\n",
      "Epoch 030 | Loss: 0.941497 | L2 Dist: 35.702042 | Cosine Sim: 0.935312\n",
      "Epoch 032 | Loss: 0.912739 | L2 Dist: 35.106148 | Cosine Sim: 0.937644\n",
      "\n",
      "Final Evaluation:\n",
      "Average L2 Distance: 35.106148\n",
      "Average Cosine Similarity: 0.937644\n",
      "\n",
      "Reconstruction Accuracy Metrics:\n",
      "Overall reconstruction accuracy: 88.42%\n",
      "Average component-wise accuracy: 73.72%\n",
      "Average L2 Distance: 35.106148\n",
      "Average Cosine Similarity: 0.937644\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "gives you\n",
    "Overall reconstruction accuracy: 91.87%\n",
    "using\n",
    "    latent_dim = 64\n",
    "\n",
    "\n",
    "or\n",
    "Overall reconstruction accuracy: 88.42%\n",
    "using\n",
    "    latent_dim = 32\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.05),\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.LayerNorm(dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.fc(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.GELU(),\n",
    "            ResidualBlock(1024),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.GELU(),\n",
    "            ResidualBlock(512),\n",
    "\n",
    "            nn.Linear(512, latent_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.GELU(),\n",
    "            ResidualBlock(512),\n",
    "\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.GELU(),\n",
    "            ResidualBlock(1024),\n",
    "\n",
    "            nn.Linear(1024, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def train_autoencoder(trajectories, latent_dim=64, batch_size=128, num_epochs=100, lr=1e-3):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    trajectory_lengths = [t.shape[0] for t in trajectories]\n",
    "    input_dim = trajectories[0].shape[1]\n",
    "\n",
    "    stacked_trajectories = torch.cat(trajectories, dim=0)\n",
    "\n",
    "    # Create dataset and loader\n",
    "    dataset = TensorDataset(stacked_trajectories)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Initialize models\n",
    "    encoder = Encoder(input_dim, latent_dim).to(device)\n",
    "    decoder = Decoder(input_dim, latent_dim).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for (batch,) in loader:\n",
    "            x = batch.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            z = encoder(x)\n",
    "            x_recon = decoder(z)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(x_recon, x)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item() * x.size(0)\n",
    "\n",
    "        epoch_loss /= len(dataset)\n",
    "\n",
    "        # Evaluation\n",
    "        if epoch % 10 == 0 or epoch == num_epochs:\n",
    "            encoder.eval()\n",
    "            decoder.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Compute Euclidean distance \n",
    "                val_batch = stacked_trajectories.to(device)\n",
    "                val_recon = decoder(encoder(val_batch))\n",
    "                l2_dist = torch.norm(val_recon - val_batch, dim=1).mean().item()\n",
    "\n",
    "                # Cosine similarity \n",
    "                cos_sim = nn.functional.cosine_similarity(val_recon, val_batch, dim=1).mean().item()\n",
    "\n",
    "                print(f\"Epoch {epoch:03d} | Loss: {epoch_loss:.6f} | L2 Dist: {l2_dist:.6f} | Cosine Sim: {cos_sim:.6f}\")\n",
    "\n",
    "            if epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "\n",
    "    return encoder, decoder, trajectory_lengths\n",
    "\n",
    "def encode_trajectories(encoder, trajectories, device=None):\n",
    "    \"\"\"\n",
    "    Encode all trajectories to lower dimension while preserving trajectory structure\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    encoder.eval()\n",
    "    trajectory_lengths = [t.shape[0] for t in trajectories]\n",
    "    encoded_trajectories = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for trajectory in trajectories:\n",
    "            # Encode each trajectory\n",
    "            encoded = encoder(trajectory.to(device))\n",
    "            encoded_trajectories.append(encoded)\n",
    "\n",
    "    return encoded_trajectories, trajectory_lengths\n",
    "\n",
    "def decode_trajectories(decoder, encoded_trajectories, device=None):\n",
    "    \"\"\"\n",
    "    Decode all encoded trajectories back to original dimension\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    decoder.eval()\n",
    "    decoded_trajectories = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for encoded in encoded_trajectories:\n",
    "            # Decode each trajectory\n",
    "            decoded = decoder(encoded.to(device))\n",
    "            decoded_trajectories.append(decoded)\n",
    "\n",
    "    return decoded_trajectories\n",
    "\n",
    "def evaluate_reconstruction(original_trajectories, decoded_trajectories):\n",
    "    \"\"\"\n",
    "    Evaluate reconstruction quality across all trajectories\n",
    "    \"\"\"\n",
    "    total_l2_dist = 0\n",
    "    total_cos_sim = 0\n",
    "    total_points = 0\n",
    "\n",
    "    for orig, recon in zip(original_trajectories, decoded_trajectories):\n",
    "        if orig.device != recon.device:\n",
    "            recon = recon.to(orig.device)\n",
    "\n",
    "        # L2 distance\n",
    "        l2_dist = torch.norm(recon - orig, dim=1).mean().item()\n",
    "\n",
    "        # Cosine similarity\n",
    "        cos_sim = nn.functional.cosine_similarity(recon, orig, dim=1).mean().item()\n",
    "\n",
    "        # Weight by number of points in trajectory\n",
    "        n_points = orig.shape[0]\n",
    "        total_l2_dist += l2_dist * n_points\n",
    "        total_cos_sim += cos_sim * n_points\n",
    "        total_points += n_points\n",
    "\n",
    "    avg_l2_dist = total_l2_dist / total_points\n",
    "    avg_cos_sim = total_cos_sim / total_points\n",
    "\n",
    "    return {\n",
    "        \"avg_l2_distance\": avg_l2_dist,\n",
    "        \"avg_cosine_similarity\": avg_cos_sim\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_reconstruction_accuracy(encoder, decoder, trajectories, device=None):\n",
    "    \"\"\"\n",
    "    Calculate reconstruction accuracy as a percentage for the PyTorch autoencoder\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Get encoded and decoded trajectories\n",
    "    encoded_trajectories, _ = encode_trajectories(encoder, trajectories, device)\n",
    "    decoded_trajectories = decode_trajectories(decoder, encoded_trajectories, device)\n",
    "\n",
    "    original_data = torch.cat(trajectories, dim=0).cpu().numpy()\n",
    "    reconstructed_data = torch.cat(decoded_trajectories, dim=0).cpu().numpy()\n",
    "\n",
    "    mse = np.mean(np.square(original_data - reconstructed_data))\n",
    "    variance = np.var(original_data)\n",
    "    accuracy_percentage = (1 - mse/variance) * 100\n",
    "\n",
    "    # Calculate component-wise accuracy\n",
    "    component_mse = np.mean(np.square(original_data - reconstructed_data), axis=0)\n",
    "    component_var = np.var(original_data, axis=0)\n",
    "    component_accuracy = np.mean((1 - component_mse/component_var) * 100)\n",
    "\n",
    "    metrics = evaluate_reconstruction(trajectories, decoded_trajectories)\n",
    "\n",
    "    print(\"\\nReconstruction Accuracy Metrics:\")\n",
    "    print(f\"Overall reconstruction accuracy: {accuracy_percentage:.2f}%\")\n",
    "    print(f\"Average component-wise accuracy: {component_accuracy:.2f}%\")\n",
    "    print(f\"Average L2 Distance: {metrics['avg_l2_distance']:.6f}\")\n",
    "    print(f\"Average Cosine Similarity: {metrics['avg_cosine_similarity']:.6f}\")\n",
    "\n",
    "    return {\n",
    "        \"overall_accuracy\": accuracy_percentage,\n",
    "        \"component_accuracy\": (1 - component_mse/component_var) * 100,\n",
    "        \"l2_distance\": metrics[\"avg_l2_distance\"],\n",
    "        \"cosine_similarity\": metrics[\"avg_cosine_similarity\"],\n",
    "        \"mse\": mse\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Hyperparameters\n",
    "    latent_dim = 32  # Target reduced dimension\n",
    "    batch_size = 64\n",
    "    lr = 1e-3\n",
    "    num_epochs = 32\n",
    "\n",
    "    encoder, decoder, trajectory_lengths = train_autoencoder(\n",
    "        trajectories=trajectories,\n",
    "        latent_dim=latent_dim,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=num_epochs,\n",
    "        lr=lr\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    encoded_trajectories, _ = encode_trajectories(encoder, trajectories)\n",
    "    decoded_trajectories = decode_trajectories(decoder, encoded_trajectories)\n",
    "    metrics = evaluate_reconstruction(trajectories, decoded_trajectories)\n",
    "\n",
    "    print(\"\\nFinal Evaluation:\")\n",
    "    print(f\"Average L2 Distance: {metrics['avg_l2_distance']:.6f}\")\n",
    "    print(f\"Average Cosine Similarity: {metrics['avg_cosine_similarity']:.6f}\")\n",
    "\n",
    "    accuracy_metrics = calculate_reconstruction_accuracy(encoder, decoder, trajectories)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 179505,
     "status": "ok",
     "timestamp": 1745275097280,
     "user": {
      "displayName": "gorge ja",
      "userId": "06774668278947305934"
     },
     "user_tz": -120
    },
    "id": "bwYdfKZPaS92",
    "outputId": "53408a04-3da0-4a61-d4ac-27d914198469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder...\n",
      "Epoch 1/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - cosine_similarity: 0.6532 - loss: 3.9791 - mse: 3.9098 - val_cosine_similarity: 0.7582 - val_loss: 2.9131 - val_mse: 2.8647 - learning_rate: 9.9838e-04\n",
      "Epoch 2/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - cosine_similarity: 0.7787 - loss: 2.7283 - mse: 2.6841 - val_cosine_similarity: 0.7927 - val_loss: 2.5412 - val_mse: 2.4997 - learning_rate: 9.9355e-04\n",
      "Epoch 3/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - cosine_similarity: 0.8141 - loss: 2.3399 - mse: 2.3027 - val_cosine_similarity: 0.8169 - val_loss: 2.2861 - val_mse: 2.2495 - learning_rate: 9.8552e-04\n",
      "Epoch 4/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - cosine_similarity: 0.8341 - loss: 2.1229 - mse: 2.0897 - val_cosine_similarity: 0.8275 - val_loss: 2.1740 - val_mse: 2.1395 - learning_rate: 9.7435e-04\n",
      "Epoch 5/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - cosine_similarity: 0.8451 - loss: 1.9965 - mse: 1.9655 - val_cosine_similarity: 0.8381 - val_loss: 2.0438 - val_mse: 2.0115 - learning_rate: 9.6012e-04\n",
      "Epoch 6/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - cosine_similarity: 0.8579 - loss: 1.8502 - mse: 1.8218 - val_cosine_similarity: 0.8433 - val_loss: 1.9820 - val_mse: 1.9507 - learning_rate: 9.4291e-04\n",
      "Epoch 7/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - cosine_similarity: 0.8647 - loss: 1.7692 - mse: 1.7421 - val_cosine_similarity: 0.8485 - val_loss: 1.9285 - val_mse: 1.8982 - learning_rate: 9.2284e-04\n",
      "Epoch 8/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - cosine_similarity: 0.8697 - loss: 1.7170 - mse: 1.6909 - val_cosine_similarity: 0.8517 - val_loss: 1.8838 - val_mse: 1.8542 - learning_rate: 9.0003e-04\n",
      "Epoch 9/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - cosine_similarity: 0.8744 - loss: 1.6560 - mse: 1.6308 - val_cosine_similarity: 0.8553 - val_loss: 1.8528 - val_mse: 1.8238 - learning_rate: 8.7464e-04\n",
      "Epoch 10/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - cosine_similarity: 0.8797 - loss: 1.5990 - mse: 1.5749 - val_cosine_similarity: 0.8602 - val_loss: 1.7986 - val_mse: 1.7706 - learning_rate: 8.4683e-04\n",
      "Epoch 11/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - cosine_similarity: 0.8838 - loss: 1.5459 - mse: 1.5227 - val_cosine_similarity: 0.8618 - val_loss: 1.7771 - val_mse: 1.7495 - learning_rate: 8.1677e-04\n",
      "Epoch 12/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - cosine_similarity: 0.8861 - loss: 1.5147 - mse: 1.4919 - val_cosine_similarity: 0.8645 - val_loss: 1.7489 - val_mse: 1.7218 - learning_rate: 7.8467e-04\n",
      "Epoch 13/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - cosine_similarity: 0.8891 - loss: 1.4791 - mse: 1.4569 - val_cosine_similarity: 0.8656 - val_loss: 1.7318 - val_mse: 1.7050 - learning_rate: 7.5073e-04\n",
      "Epoch 14/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - cosine_similarity: 0.8919 - loss: 1.4445 - mse: 1.4229 - val_cosine_similarity: 0.8674 - val_loss: 1.7090 - val_mse: 1.6825 - learning_rate: 7.1516e-04\n",
      "Epoch 15/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - cosine_similarity: 0.8945 - loss: 1.4128 - mse: 1.3917 - val_cosine_similarity: 0.8690 - val_loss: 1.6933 - val_mse: 1.6671 - learning_rate: 6.7821e-04\n",
      "Epoch 16/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - cosine_similarity: 0.8956 - loss: 1.3954 - mse: 1.3745 - val_cosine_similarity: 0.8705 - val_loss: 1.6729 - val_mse: 1.6470 - learning_rate: 6.4010e-04\n",
      "Epoch 17/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - cosine_similarity: 0.8978 - loss: 1.3707 - mse: 1.3503 - val_cosine_similarity: 0.8710 - val_loss: 1.6649 - val_mse: 1.6391 - learning_rate: 6.0109e-04\n",
      "Epoch 18/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - cosine_similarity: 0.9005 - loss: 1.3389 - mse: 1.3190 - val_cosine_similarity: 0.8734 - val_loss: 1.6381 - val_mse: 1.6128 - learning_rate: 5.6142e-04\n",
      "Epoch 19/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - cosine_similarity: 0.9033 - loss: 1.3082 - mse: 1.2888 - val_cosine_similarity: 0.8743 - val_loss: 1.6276 - val_mse: 1.6025 - learning_rate: 5.2136e-04\n",
      "Epoch 20/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - cosine_similarity: 0.9047 - loss: 1.2859 - mse: 1.2668 - val_cosine_similarity: 0.8750 - val_loss: 1.6221 - val_mse: 1.5971 - learning_rate: 4.8115e-04\n",
      "Epoch 21/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - cosine_similarity: 0.9062 - loss: 1.2664 - mse: 1.2476 - val_cosine_similarity: 0.8756 - val_loss: 1.6134 - val_mse: 1.5886 - learning_rate: 4.4108e-04\n",
      "Epoch 22/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - cosine_similarity: 0.9084 - loss: 1.2419 - mse: 1.2236 - val_cosine_similarity: 0.8768 - val_loss: 1.5949 - val_mse: 1.5702 - learning_rate: 4.0138e-04\n",
      "Epoch 23/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - cosine_similarity: 0.9089 - loss: 1.2358 - mse: 1.2176 - val_cosine_similarity: 0.8776 - val_loss: 1.5890 - val_mse: 1.5645 - learning_rate: 3.6232e-04\n",
      "Epoch 24/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - cosine_similarity: 0.9105 - loss: 1.2116 - mse: 1.1937 - val_cosine_similarity: 0.8782 - val_loss: 1.5788 - val_mse: 1.5544 - learning_rate: 3.2414e-04\n",
      "Epoch 25/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - cosine_similarity: 0.9118 - loss: 1.1998 - mse: 1.1821 - val_cosine_similarity: 0.8789 - val_loss: 1.5736 - val_mse: 1.5493 - learning_rate: 2.8711e-04\n",
      "Epoch 26/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - cosine_similarity: 0.9122 - loss: 1.1878 - mse: 1.1702 - val_cosine_similarity: 0.8796 - val_loss: 1.5637 - val_mse: 1.5396 - learning_rate: 2.5145e-04\n",
      "Epoch 27/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - cosine_similarity: 0.9138 - loss: 1.1672 - mse: 1.1499 - val_cosine_similarity: 0.8799 - val_loss: 1.5598 - val_mse: 1.5358 - learning_rate: 2.1740e-04\n",
      "Epoch 28/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - cosine_similarity: 0.9146 - loss: 1.1587 - mse: 1.1416 - val_cosine_similarity: 0.8806 - val_loss: 1.5511 - val_mse: 1.5273 - learning_rate: 1.8518e-04\n",
      "Epoch 29/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - cosine_similarity: 0.9162 - loss: 1.1436 - mse: 1.1269 - val_cosine_similarity: 0.8809 - val_loss: 1.5480 - val_mse: 1.5242 - learning_rate: 1.5499e-04\n",
      "Epoch 30/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - cosine_similarity: 0.9167 - loss: 1.1347 - mse: 1.1181 - val_cosine_similarity: 0.8812 - val_loss: 1.5442 - val_mse: 1.5204 - learning_rate: 1.2703e-04\n",
      "Epoch 31/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - cosine_similarity: 0.9172 - loss: 1.1254 - mse: 1.1088 - val_cosine_similarity: 0.8816 - val_loss: 1.5397 - val_mse: 1.5160 - learning_rate: 1.0148e-04\n",
      "Epoch 32/32\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - cosine_similarity: 0.9179 - loss: 1.1180 - mse: 1.1016 - val_cosine_similarity: 0.8816 - val_loss: 1.5399 - val_mse: 1.5162 - learning_rate: 7.8511e-05\n",
      "Encoding trajectories...\n",
      "Decoding trajectories...\n",
      "Evaluating reconstruction quality...\n",
      "\n",
      "Final Evaluation:\n",
      "Average MSE: 1.073840\n",
      "Average Cosine Similarity: 0.919632\n",
      "Overall MSE: 1.073838\n",
      "Overall reconstruction accuracy: 85.26%\n",
      "Average component-wise accuracy: 67.99%\n",
      "Median component-wise accuracy: 66.42%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "gives you\n",
    "\n",
    "Overall reconstruction accuracy: 85%\n",
    "using\n",
    "    latent_dim = 32\n",
    "\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, Model, optimizers, losses, metrics\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ResidualBlock(layers.Layer):\n",
    "    def __init__(self, dim, dropout_rate=0.05):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.layer_norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dense1 = layers.Dense(dim, activation=None)\n",
    "        self.activation = layers.Activation('swish')  # Using Swish activation (SiLU)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.layer_norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dense2 = layers.Dense(dim, activation=None)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.layer_norm1(inputs)\n",
    "        x = self.dense1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = self.dense2(x)\n",
    "        return x + inputs  # Residual connection\n",
    "\n",
    "class TFAutoencoder:\n",
    "    def __init__(self, input_dim=1536, latent_dim=64):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = self._build_encoder()\n",
    "        self.decoder = self._build_decoder()\n",
    "        self.model = self._build_autoencoder()\n",
    "\n",
    "    def _build_encoder(self):\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "\n",
    "        # Initial projection\n",
    "        x = layers.Dense(1024)(inputs)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = layers.Activation('swish')(x)\n",
    "\n",
    "        # First residual block\n",
    "        x = ResidualBlock(1024)(x)\n",
    "\n",
    "        # Middle layers\n",
    "        x = layers.Dense(512)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = layers.Activation('swish')(x)\n",
    "\n",
    "        # Second residual block\n",
    "        x = ResidualBlock(512)(x)\n",
    "\n",
    "        # Final projection to latent space\n",
    "        encoded = layers.Dense(self.latent_dim)(x)\n",
    "\n",
    "        return Model(inputs, encoded, name=\"encoder\")\n",
    "\n",
    "    def _build_decoder(self):\n",
    "        encoded_inputs = layers.Input(shape=(self.latent_dim,))\n",
    "\n",
    "        # Initial projection\n",
    "        x = layers.Dense(512)(encoded_inputs)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = layers.Activation('swish')(x)\n",
    "\n",
    "        # First residual block\n",
    "        x = ResidualBlock(512)(x)\n",
    "\n",
    "        # Middle layers\n",
    "        x = layers.Dense(1024)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = layers.Activation('swish')(x)\n",
    "\n",
    "        # Second residual block\n",
    "        x = ResidualBlock(1024)(x)\n",
    "\n",
    "        # Final projection back to original space\n",
    "        decoded = layers.Dense(self.input_dim)(x)\n",
    "\n",
    "        return Model(encoded_inputs, decoded, name=\"decoder\")\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        inputs = layers.Input(shape=(self.input_dim,))\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return Model(inputs, decoded, name=\"autoencoder\")\n",
    "\n",
    "    def compile(self, learning_rate=1e-3):\n",
    "        lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "            initial_learning_rate=learning_rate,\n",
    "            decay_steps=10000\n",
    "        )\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "        def combined_loss(y_true, y_pred):\n",
    "            # MSE \n",
    "            mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "            # Cosine similarity \n",
    "            y_true_norm = tf.nn.l2_normalize(y_true, axis=1)\n",
    "            y_pred_norm = tf.nn.l2_normalize(y_pred, axis=1)\n",
    "            cosine_loss = 1 - tf.reduce_mean(tf.reduce_sum(y_true_norm * y_pred_norm, axis=1))\n",
    "\n",
    "            return mse + 0.2 * cosine_loss\n",
    "\n",
    "        self.model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=combined_loss,\n",
    "            metrics=[\n",
    "                'mse',  # Mean Squared Error\n",
    "                tf.keras.metrics.CosineSimilarity(axis=1)  # Cosine similarity\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def train(self, trajectories, batch_size=128, epochs=100, validation_split=0.1):\n",
    "        # Stack all trajectories while keeping track of lengths\n",
    "        trajectory_lengths = [t.shape[0] for t in trajectories]\n",
    "        stacked_data = np.vstack([t.numpy() if isinstance(t, tf.Tensor) else t for t in trajectories])\n",
    "\n",
    "        stacked_tensor = tf.convert_to_tensor(stacked_data, dtype=tf.float32)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "        ]\n",
    "\n",
    "        # Train the model\n",
    "        history = self.model.fit(\n",
    "            stacked_tensor, stacked_tensor,  # Autoencoder: input = target\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=validation_split,\n",
    "            callbacks=callbacks,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        return history, trajectory_lengths\n",
    "\n",
    "    def encode_trajectories(self, trajectories):\n",
    "        \"\"\"Encode each trajectory individually while preserving structure\"\"\"\n",
    "        encoded_trajectories = []\n",
    "        for trajectory in trajectories:\n",
    "            if not isinstance(trajectory, (np.ndarray, tf.Tensor)):\n",
    "                trajectory = trajectory.numpy()\n",
    "\n",
    "            if not isinstance(trajectory, tf.Tensor):\n",
    "                trajectory = tf.convert_to_tensor(trajectory, dtype=tf.float32)\n",
    "\n",
    "            # Encode \n",
    "            encoded = self.encoder.predict(trajectory, verbose=0)\n",
    "            encoded_trajectories.append(encoded)\n",
    "\n",
    "        return encoded_trajectories\n",
    "\n",
    "    def decode_trajectories(self, encoded_trajectories):\n",
    "        \"\"\"Decode each encoded trajectory back to original dimensionality\"\"\"\n",
    "        decoded_trajectories = []\n",
    "        for encoded in encoded_trajectories:\n",
    "            if not isinstance(encoded, tf.Tensor):\n",
    "                encoded = tf.convert_to_tensor(encoded, dtype=tf.float32)\n",
    "\n",
    "            # Decode \n",
    "            decoded = self.decoder.predict(encoded, verbose=0)\n",
    "            decoded_trajectories.append(decoded)\n",
    "\n",
    "        return decoded_trajectories\n",
    "\n",
    "    def evaluate_reconstruction(self, original_trajectories, decoded_trajectories=None):\n",
    "        \"\"\"Evaluate reconstruction quality across all trajectories\"\"\"\n",
    "        if decoded_trajectories is None:\n",
    "            # If decoded trajectories not provided, encode and decode originals\n",
    "            encoded = self.encode_trajectories(original_trajectories)\n",
    "            decoded_trajectories = self.decode_trajectories(encoded)\n",
    "\n",
    "        total_mse = 0\n",
    "        total_cosine_sim = 0\n",
    "        total_points = 0\n",
    "\n",
    "        for i, (orig, recon) in enumerate(zip(original_trajectories, decoded_trajectories)):\n",
    "            if isinstance(orig, tf.Tensor):\n",
    "                orig = orig.numpy()\n",
    "            if isinstance(recon, tf.Tensor):\n",
    "                recon = recon.numpy()\n",
    "            if not isinstance(orig, np.ndarray):\n",
    "                orig = orig.numpy()\n",
    "            if not isinstance(recon, np.ndarray):\n",
    "                recon = recon.numpy()\n",
    "\n",
    "            # Calculate MSE\n",
    "            mse = np.mean(np.square(orig - recon))\n",
    "\n",
    "            # Calculate cosine similarity\n",
    "            orig_norm = orig / np.linalg.norm(orig, axis=1, keepdims=True)\n",
    "            recon_norm = recon / np.linalg.norm(recon, axis=1, keepdims=True)\n",
    "            cosine_sim = np.mean(np.sum(orig_norm * recon_norm, axis=1))\n",
    "\n",
    "            # Weight by trajectory length\n",
    "            n_points = orig.shape[0]\n",
    "            total_mse += mse * n_points\n",
    "            total_cosine_sim += cosine_sim * n_points\n",
    "            total_points += n_points\n",
    "\n",
    "        avg_mse = total_mse / total_points\n",
    "        avg_cosine_sim = total_cosine_sim / total_points\n",
    "\n",
    "        return {\n",
    "            \"mse\": avg_mse,\n",
    "            \"cosine_similarity\": avg_cosine_sim\n",
    "        }\n",
    "\n",
    "def prepare_tf_data(trajectories):\n",
    "    \"\"\"Convert PyTorch trajectories to TensorFlow tensors if needed\"\"\"\n",
    "    tf_trajectories = []\n",
    "    for trajectory in trajectories:\n",
    "        if not isinstance(trajectory, (np.ndarray, tf.Tensor)):\n",
    "            # Convert PyTorch tensor to numpy\n",
    "            trajectory = trajectory.cpu().numpy()\n",
    "        tf_trajectories.append(trajectory)\n",
    "    return tf_trajectories\n",
    "\n",
    "def process_trajectories(trajectories):\n",
    "    \"\"\"Main function to process trajectories with TensorFlow autoencoder\"\"\"\n",
    "    tf_trajectories = prepare_tf_data(trajectories)\n",
    "\n",
    "    input_dim = tf_trajectories[0].shape[1]\n",
    "    latent_dim = 32  # Target reduced dimension\n",
    "\n",
    "    autoencoder = TFAutoencoder(input_dim=input_dim, latent_dim=latent_dim)\n",
    "    autoencoder.compile(learning_rate=1e-3)\n",
    "\n",
    "    # Train the autoencoder\n",
    "    print(\"Training autoencoder...\")\n",
    "    history, trajectory_lengths = autoencoder.train(\n",
    "        tf_trajectories,\n",
    "        batch_size=64,\n",
    "        epochs=32,\n",
    "        validation_split=0.1\n",
    "    )\n",
    "\n",
    "    print(\"Encoding trajectories...\")\n",
    "    encoded_trajectories = autoencoder.encode_trajectories(tf_trajectories)\n",
    "    print(\"Decoding trajectories...\")\n",
    "    decoded_trajectories = autoencoder.decode_trajectories(encoded_trajectories)\n",
    "\n",
    "    print(\"Evaluating reconstruction quality...\")\n",
    "    metrics = autoencoder.evaluate_reconstruction(tf_trajectories, decoded_trajectories)\n",
    "\n",
    "    print(\"\\nFinal Evaluation:\")\n",
    "    print(f\"Average MSE: {metrics['mse']:.6f}\")\n",
    "    print(f\"Average Cosine Similarity: {metrics['cosine_similarity']:.6f}\")\n",
    "\n",
    "    return autoencoder, encoded_trajectories, metrics\n",
    "\n",
    "\n",
    "def test_component_reconstruction(autoencoder, test_trajectories):\n",
    "    if not isinstance(test_trajectories[0], (np.ndarray, tf.Tensor)):\n",
    "        test_trajectories = prepare_tf_data(test_trajectories)\n",
    "\n",
    "    encoded = autoencoder.encode_trajectories(test_trajectories)\n",
    "    reconstructed = autoencoder.decode_trajectories(encoded)\n",
    "\n",
    "    all_orig = np.vstack([t if isinstance(t, np.ndarray) else t.numpy() for t in test_trajectories])\n",
    "    all_recon = np.vstack([r if isinstance(r, np.ndarray) else r.numpy() for r in reconstructed])\n",
    "\n",
    "    # Calculate MSE \n",
    "    component_mse = np.mean(np.square(all_orig - all_recon), axis=0)\n",
    "\n",
    "    # Summary statistics\n",
    "    avg_mse = np.mean(component_mse)\n",
    "\n",
    "    print(f\"Overall MSE: {avg_mse:.6f}\")\n",
    "\n",
    "    return component_mse\n",
    "\n",
    "def calculate_reconstruction_percentage(autoencoder, test_trajectories):\n",
    "    if not isinstance(test_trajectories[0], (np.ndarray, tf.Tensor)):\n",
    "        test_trajectories = prepare_tf_data(test_trajectories)\n",
    "\n",
    "    encoded = autoencoder.encode_trajectories(test_trajectories)\n",
    "    reconstructed = autoencoder.decode_trajectories(encoded)\n",
    "\n",
    "    all_orig = np.vstack([t if isinstance(t, np.ndarray) else t.numpy() for t in test_trajectories])\n",
    "    all_recon = np.vstack([r if isinstance(r, np.ndarray) else r.numpy() for r in reconstructed])\n",
    "\n",
    "    mse = np.mean(np.square(all_orig - all_recon))\n",
    "    variance = np.var(all_orig)\n",
    "    accuracy_percentage = (1 - mse/variance) * 100\n",
    "\n",
    "    # Calculate component-wise accuracy\n",
    "    component_mse = np.mean(np.square(all_orig - all_recon), axis=0)\n",
    "    component_var = np.var(all_orig, axis=0)\n",
    "    component_accuracy = (1 - component_mse/component_var) * 100\n",
    "\n",
    "    print(f\"Overall reconstruction accuracy: {accuracy_percentage:.2f}%\")\n",
    "    print(f\"Average component-wise accuracy: {np.mean(component_accuracy):.2f}%\")\n",
    "    print(f\"Median component-wise accuracy: {np.median(component_accuracy):.2f}%\")\n",
    "\n",
    "    return {\n",
    "        \"overall_accuracy\": accuracy_percentage,\n",
    "        \"component_accuracy\": component_accuracy\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    autoencoder, encoded_trajectories, metrics = process_trajectories(trajectories)\n",
    "    test_component_reconstruction(autoencoder, trajectories)\n",
    "    calculate_reconstruction_percentage(autoencoder, trajectories)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
