

Large Language Models (LLMs) have become an important part of our lives.

Despite these developments, little is known about the internal dynamics of the model.



In this paper we show that LLMs trajectories exhibit sensitivity to initial conditions (SIC) and a positive maximum lyapunov exponent. They also share structural similarities with other typical chaotic systems suc as Lorenz systems as evidenced by the Recurrence Plots (RP). We discuss how challenges associated with the high dimensionality of the data can be handled and which distance metrics are suitable for such an analysis.

These results show that LLMs posses many features of chaotic systems, which is relevant for future development in the field.



These are highly nonlinear models
Chaos theory studies deterministic nonlinear models

We believe the tools from Nonlinear Dynamics and Chaos Theory provide valuable insights into the inner representations of LLMs.

We believe studying LLMs as nonlinear systems using the tools from Chaos Theory is interesting





Using Recurrence Plots (and RQA) we found that the LLM's hidden state trajectories share similarities with typical chaotic systems like Lorenz systems, and that they exhibit sensitivity to initial conditions (SIC) and positive maximum lyapunov exponent.











